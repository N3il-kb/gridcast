{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datacenter Score Analysis\n",
        "\n",
        "This notebook ingests recent market and weather data to compute a composite datacenter siting score across U.S. grid regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "Ensure required dependencies are available for the workflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install --quiet pandas numpy requests plotly matplotlib prophet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Global Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from prophet import Prophet\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "px.defaults.template = 'plotly_white'\n",
        "\n",
        "CACHE_DIR = Path('cache')\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "EIA_BASE_URL = 'https://api.eia.gov/v2/electricity/rto/region-data/data/'\n",
        "EIA_API_KEY = os.getenv('EIA_API_KEY', 'DEMO_KEY')\n",
        "HISTORICAL_DAYS = 90\n",
        "PROPHET_LOOKBACK_DAYS = 60\n",
        "FORECAST_HOURS = 24 * 7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EIA Hourly Demand Fetching\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _cache_path_for_region(region: str) -> Path:\n",
        "    return CACHE_DIR / f'eia_{region.lower()}_hourly.csv'\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def fetch_eia_hourly(region: str) -> pd.DataFrame:\n",
        "    \"\"\"Fetch the most recent 90 days of hourly demand for the requested EIA region.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    region : str\n",
        "        The EIA RTO/region code (e.g., 'CAL', 'TEX').\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame with columns [datetime, demand_MW, region].\n",
        "    \"\"\"\n",
        "    cache_path = _cache_path_for_region(region)\n",
        "    end = datetime.utcnow()\n",
        "    start = end - timedelta(days=HISTORICAL_DAYS)\n",
        "    params = {\n",
        "        'api_key': EIA_API_KEY,\n",
        "        'data[0]': 'value',\n",
        "        'facets[region][]': region,\n",
        "        'frequency': 'hourly',\n",
        "        'start': start.strftime('%Y-%m-%dT%H'),\n",
        "        'end': end.strftime('%Y-%m-%dT%H'),\n",
        "        'sort[0][column]': 'period',\n",
        "        'sort[0][direction]': 'desc',\n",
        "        'offset': 0,\n",
        "        'length': 5000,\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(EIA_BASE_URL, params=params, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        payload = response.json()\n",
        "        data = payload.get('response', {}).get('data', [])\n",
        "        if not data:\n",
        "            raise ValueError('Empty dataset returned from EIA API.')\n",
        "        records = []\n",
        "        for item in data:\n",
        "            period = item.get('period')\n",
        "            value = item.get('value')\n",
        "            if period is None or value is None:\n",
        "                continue\n",
        "            records.append({\n",
        "                'datetime': pd.to_datetime(period),\n",
        "                'demand_MW': float(value),\n",
        "                'region': region,\n",
        "            })\n",
        "        df = pd.DataFrame(records)\n",
        "        if df.empty:\n",
        "            raise ValueError('No valid records parsed from EIA response.')\n",
        "        df = df.drop_duplicates(subset='datetime').sort_values('datetime')\n",
        "        df = df[df['datetime'] >= start]\n",
        "        df.to_csv(cache_path, index=False)\n",
        "        return df\n",
        "    except Exception as exc:\n",
        "        print(f'EIA API fetch failed for {region}: {exc}')\n",
        "        if cache_path.exists():\n",
        "            print(f'Loading cached data for {region} from {cache_path}.')\n",
        "            df = pd.read_csv(cache_path, parse_dates=['datetime'])\n",
        "            return df\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecasting and Grid Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _prepare_hourly_series(df_region: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df_region.empty:\n",
        "        raise ValueError('Region dataframe is empty.')\n",
        "    df = df_region.copy()\n",
        "    df = df.drop_duplicates(subset='datetime').sort_values('datetime')\n",
        "    df = df.set_index('datetime')\n",
        "    full_range = pd.date_range(df.index.min(), df.index.max(), freq='H')\n",
        "    df = df.reindex(full_range)\n",
        "    df['demand_MW'] = df['demand_MW'].interpolate(method='time')\n",
        "    df['region'] = df_region['region'].iloc[0]\n",
        "    return df\n",
        "\n",
        "\n",
        "def forecast_peak_demand(df_region: pd.DataFrame) -> float:\n",
        "    prepped = _prepare_hourly_series(df_region)\n",
        "    recent_start = prepped.index.max() - timedelta(days=PROPHET_LOOKBACK_DAYS)\n",
        "    df_recent = prepped[prepped.index >= recent_start]\n",
        "    prophet_df = df_recent.reset_index().rename(columns={'index': 'ds', 'demand_MW': 'y'})\n",
        "    model = Prophet(\n",
        "        growth='flat',\n",
        "        daily_seasonality=True,\n",
        "        weekly_seasonality=True,\n",
        "        yearly_seasonality=False\n",
        "    )\n",
        "    model.add_country_holidays(country_name='US')\n",
        "    model.fit(prophet_df)\n",
        "    future = model.make_future_dataframe(periods=FORECAST_HOURS, freq='H', include_history=False)\n",
        "    forecast = model.predict(future)\n",
        "    peak_forecast = float(forecast['yhat'].max())\n",
        "    return peak_forecast\n",
        "\n",
        "\n",
        "def compute_volatility(df_region: pd.DataFrame) -> float:\n",
        "    prepped = _prepare_hourly_series(df_region)\n",
        "    rolling_std = prepped['demand_MW'].rolling(window=24, min_periods=1).std()\n",
        "    return float(rolling_std.iloc[-1])\n",
        "\n",
        "\n",
        "def compute_renewable_proxy(df_region: pd.DataFrame) -> float:\n",
        "    prepped = _prepare_hourly_series(df_region)\n",
        "    mean_load = prepped['demand_MW'].mean()\n",
        "    return float(1.0 / (1.0 + mean_load))\n",
        "\n",
        "\n",
        "def compute_carbon_proxy(renewable_proxy: float) -> float:\n",
        "    return float(1.0 - renewable_proxy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weather Data via Open-Meteo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@lru_cache(maxsize=None)\n",
        "def fetch_temperature(lat: float, lon: float) -> float:\n",
        "    url = 'https://api.open-meteo.com/v1/forecast'\n",
        "    params = {\n",
        "        'latitude': lat,\n",
        "        'longitude': lon,\n",
        "        'daily': 'temperature_2m_mean',\n",
        "        'past_days': 60,\n",
        "        'timezone': 'UTC',\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        temps = data.get('daily', {}).get('temperature_2m_mean', [])\n",
        "        if not temps:\n",
        "            raise ValueError('Temperature series is empty.')\n",
        "        return float(np.mean(temps))\n",
        "    except Exception as exc:\n",
        "        print(f'Open-Meteo fetch failed for ({lat}, {lon}): {exc}')\n",
        "        return float('nan')\n",
        "\n",
        "\n",
        "region_coords = {\n",
        "    'CAL': (36.5, -119.5),\n",
        "    'CAR': (35.5, -80.0),\n",
        "    'CENT': (38.5, -94.5),\n",
        "    'FLA': (28.0, -82.0),\n",
        "    'MIDA': (39.0, -77.0),\n",
        "    'MIDW': (42.0, -89.0),\n",
        "    'NE': (42.5, -72.5),\n",
        "    'NY': (42.9, -75.3),\n",
        "    'NW': (45.5, -120.5),\n",
        "    'SE': (33.0, -84.0),\n",
        "    'SW': (36.0, -111.5),\n",
        "    'TEN': (36.0, -86.0),\n",
        "    'TEX': (31.0, -99.0),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Datacenter Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "records = []\n",
        "for region, (lat, lon) in region_coords.items():\n",
        "    try:\n",
        "        df_region = fetch_eia_hourly(region)\n",
        "    except Exception as exc:\n",
        "        print(f'Skipping region {region} due to data issues: {exc}')\n",
        "        continue\n",
        "    df_region = df_region.sort_values('datetime')\n",
        "    latest_demand = float(df_region['demand_MW'].iloc[-1]) if not df_region.empty else float('nan')\n",
        "    volatility = compute_volatility(df_region)\n",
        "    peak = forecast_peak_demand(df_region)\n",
        "    renewable_proxy = compute_renewable_proxy(df_region)\n",
        "    carbon_proxy = compute_carbon_proxy(renewable_proxy)\n",
        "    avg_temp = fetch_temperature(lat, lon)\n",
        "    records.append({\n",
        "        'region': region,\n",
        "        'price': latest_demand,\n",
        "        'peak_forecast': peak,\n",
        "        'volatility': volatility,\n",
        "        'renewable_proxy': renewable_proxy,\n",
        "        'carbon_proxy': carbon_proxy,\n",
        "        'avg_temp': avg_temp,\n",
        "        'lat': lat,\n",
        "        'lon': lon,\n",
        "    })\n",
        "\n",
        "dc_df = pd.DataFrame(records)\n",
        "if dc_df.empty:\n",
        "    dc_df = pd.DataFrame(columns=['region', 'price', 'peak_forecast', 'volatility', 'renewable_proxy', 'carbon_proxy', 'avg_temp', 'lat', 'lon'])\n",
        "else:\n",
        "    metrics_to_normalize = {\n",
        "        'price': 'price_norm',\n",
        "        'peak_forecast': 'peak_norm',\n",
        "        'volatility': 'volatility_norm',\n",
        "        'renewable_proxy': 'renewable_norm',\n",
        "        'carbon_proxy': 'carbon_norm',\n",
        "        'avg_temp': 'temp_norm',\n",
        "    }\n",
        "    for metric, norm_col in metrics_to_normalize.items():\n",
        "        col = dc_df[metric]\n",
        "        col_min, col_max = col.min(), col.max()\n",
        "        if np.isfinite(col_min) and np.isfinite(col_max) and col_max != col_min:\n",
        "            dc_df[norm_col] = (col - col_min) / (col_max - col_min)\n",
        "        else:\n",
        "            dc_df[norm_col] = 0.0\n",
        "    dc_df['profitability'] = (\n",
        "        0.40 * (1 - dc_df['price_norm']) +\n",
        "        0.30 * (1 - dc_df['peak_norm']) +\n",
        "        0.30 * (1 - dc_df['volatility_norm'])\n",
        "    )\n",
        "    dc_df['sustainability'] = (\n",
        "        0.35 * dc_df['renewable_norm'] +\n",
        "        0.30 * (1 - dc_df['carbon_norm']) +\n",
        "        0.20 * (1 - dc_df['temp_norm']) +\n",
        "        0.15 * dc_df['renewable_norm']\n",
        "    )\n",
        "    dc_df['hybrid'] = 0.5 * dc_df['profitability'] + 0.5 * dc_df['sustainability']\n",
        "    dc_df = dc_df.sort_values('hybrid', ascending=False).reset_index(drop=True)\n",
        "\n",
        "final_columns = ['region', 'price', 'peak_forecast', 'volatility', 'renewable_proxy', 'carbon_proxy', 'avg_temp', 'profitability', 'sustainability', 'hybrid']\n",
        "for col in final_columns:\n",
        "    if col not in dc_df.columns:\n",
        "        dc_df[col] = np.nan\n",
        "dc_df_final = dc_df[final_columns]\n",
        "dc_df_final.to_csv('datacenter_scores.csv', index=False)\n",
        "dc_df_final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if not dc_df.empty:\n",
        "    melted = dc_df.melt(id_vars=['region'], value_vars=['profitability', 'sustainability', 'hybrid'], var_name='metric', value_name='score')\n",
        "    fig = px.bar(melted, x='region', y='score', color='metric', barmode='group', title='Datacenter Score Components by Region')\n",
        "    fig.show()\n",
        "else:\n",
        "    print('No data available for bar chart visualization.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if not dc_df.empty:\n",
        "    fig_map = px.scatter_geo(\n",
        "        dc_df,\n",
        "        lat='lat',\n",
        "        lon='lon',\n",
        "        size='hybrid',\n",
        "        color='hybrid',\n",
        "        hover_name='region',\n",
        "        projection='natural earth',\n",
        "        title='Hybrid Datacenter Score Across U.S. Grid Regions'\n",
        "    )\n",
        "    fig_map.update_layout(geo_scope='usa')\n",
        "    fig_map.show()\n",
        "else:\n",
        "    print('No data available for map visualization.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}